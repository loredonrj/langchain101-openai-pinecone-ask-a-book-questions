{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"/Users/rloredon/Downloads/The-Field-Guide-to-Data-Science.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in your data\n",
      "There are 156594 characters in your sample document\n",
      "Here is a sample: T H E F I ELD G U I D E\n",
      "\n",
      "to D A T A S C I E N C E\n",
      "\n",
      "© COPYRIGHT 2013 BOOZ ALLEN HAMILTON INC. ALL RIGHTS RESERVED.\n",
      "\n",
      "FOREWORDEvery aspect of our lives, from life-saving disease treatments, to national s\n"
     ]
    }
   ],
   "source": [
    "# let's print some info about our document\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your sample document')\n",
    "print (f'Here is a sample: {data[0].page_content[:200]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking our \"Document\" stored in the data variable up into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll split our data into chunks around 500 characters each with a 50 character overlap. These are relatively small.\n",
    "text_splitter = RecursiveCharacterTextSplitter (chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 441 documents\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many small chunks we have\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's print one just to see , say the 250th one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='the diagram to the appropriate class of analytic techniques and provide recommendations for a few techniques to consider.(cid:110)(cid:3)TIP: There are several situations where dimensionality reduction may be needed: ›Models fail to converge ›Models produce results equivalent to random chance ›You lack the computational power to perform operations across the feature space ›You do not know which aspects of the data are the most important(cid:111)(cid:3)(cid:3)Feature Extraction is a broad topic', metadata={'source': '/Users/rloredon/Downloads/The-Field-Guide-to-Data-Science.pdf'})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embeddings of your documents to get ready for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_pinecone.vectorstores import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we'll get our embeddings engine going. We'll use OpenAI's ada today.\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pinecone for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "#connect to pinecone\n",
    "\n",
    "#we go create an index named \"langchain1\" in pinecone api (choose 1536 dimensions, for working with openai)\n",
    "index_name = \"langchain1\"\n",
    "\n",
    "#get our locally generated openai embeddings and pass them over to pinecone vectorstore in the cloud. the number of vectors = number of documents\n",
    "vectorstore = PineconeVectorStore.from_texts([t.page_content for t in texts],embedding=embeddings,index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's ask our book questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='with other Data Science teams is critical to the success.'),\n",
       " Document(page_content='Building a team starts with identifying existing staff within an organization who have a high aptitude for Data Science. Good candidates will have a formal background in any of the three foundational technical skills we mentioned, and will most importantly have the personality traits necessary for Data Science. They may often have advanced (masters or higher) degrees, but not always. The very first staff you identify should also have good leadership traits and a sense of purpose for the'),\n",
       " Document(page_content='Performing Data Science requires the extraction of timely, actionable information from diverse data sources to drive data products. Examples of data products include answers to questions such as: “Which of my products should I advertise more heavily to increase profit? How can I improve my compliance program, while reducing costs? What manufacturing process change will allow me to build a better product?” The key to answering these questions is: understand the data you have and what the data'),\n",
       " Document(page_content='2\\n\\nData Science'),\n",
       " Document(page_content='who and the how. Many people have put forth their thoughts on single aspects of Data Science. We believe we can offer a broad perspective on the conceptual models, tradecraft, processes and culture of Data Science. Companies with strong Data Science teams often focus on a single class of problems – graph algorithms for social network analysis and recommender models for online shopping are two notable examples. Booz Allen is different. In our role as consultants, we support a diverse set of')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the characteristics of a good data science team ?\"\n",
    "query_results = vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's chain those search results  into OpenAI to get our answer back in natural language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv240512",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
